{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b9b9bdd-bea8-4bf0-a6d6-a03906a04bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from determined.experimental import client\n",
    "from determined.common import yaml\n",
    "import pathlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc1a8473-dd94-4aea-a7a1-f48bf51f58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53890cfa-7db4-4d41-907e-7cda7ab9f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = pathlib.Path(\"./cifar10\")\n",
    "exp_conf_path = model_dir / \"const.yaml\"\n",
    "exp_conf = yaml.safe_load(exp_conf_path.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8344a0e4-0e09-4a4c-b7bd-8f32fd4e9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metric_name = \"validation_error\"\n",
    "hp_search = {\n",
    "    \"learning_rate\": [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "terminal_trial_states = [\n",
    "    \"CANCELED\", \"COMPLETED\", \"ERROR\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54b06182-4b77-4da7-8332-606164cf2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_trial(trial, interval):\n",
    "    prev_val_steps = None\n",
    "    prev_best_val = None\n",
    "    steps_threshold = 5\n",
    "    \n",
    "    while trial.state.name not in terminal_trial_states:\n",
    "        trial.reload()\n",
    "        print(f\"Trial {trial.id}: {trial.state.name}\")\n",
    "        summary_metrics = trial.summary_metrics\n",
    "        if not summary_metrics or \"validation_metrics\" not in summary_metrics:\n",
    "            time.sleep(interval)\n",
    "            continue\n",
    "        current_val = summary_metrics[\"validation_metrics\"][val_metric_name][\"min\"]\n",
    "        current_steps = summary_metrics[\"validation_metrics\"][val_metric_name][\"count\"]\n",
    "        \n",
    "        if prev_val_steps is not None and prev_best_val is not None:\n",
    "            early_stop = should_early_stop(prev_best_val, prev_val_steps, current_val, current_steps, steps_threshold)\n",
    "            if early_stop:\n",
    "                print(f\"Early stopping trial {trial.id} due to no improvement for {val_metric_name} for {steps_threshold} steps.\")\n",
    "                trial.kill()\n",
    "                \n",
    "        time.sleep(interval)\n",
    "\n",
    "def create_experiment_with_hparams(hp_name, hp_val, val_metric_name, trial_queue):\n",
    "    print(f\"Starting experiment with {hp_name}={hp_val}\")\n",
    "    exp_conf[\"hyperparameters\"][hp_name] = hp_val\n",
    "\n",
    "    exp = client.create_experiment(config=exp_conf, model_dir=model_dir)\n",
    "\n",
    "    trial = exp.await_first_trial()\n",
    "    trial_queue.put(trial.id)\n",
    "\n",
    "    monitor_trial(trial, 5)\n",
    "    \n",
    "def should_early_stop(prev_best_val, prev_val_steps, current_best_val, current_val_steps, stop_threshold):\n",
    "    \"\"\"\n",
    "    Primitive early stopping: returns True if a trial's searcher validation metric has not improved within a specified number of steps, else False.\n",
    "    \"\"\"\n",
    "    if prev_val_steps + stop_threshold <= current_val_steps and current_best_val == prev_best_val:\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b8297af-6466-43d8-b0f0-e5c70a21314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment with learning_rate=0.0001\n",
      "Starting experiment with learning_rate=0.001d 0 files\n",
      "Preparing files to send to master... 6.5KB and 6 files                                                        \n",
      "Preparing files to send to master... 6.5KB and 6 files\n",
      "Trial 61 QUEUED\n",
      "Trial 62 QUEUED\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 62 RUNNING\n",
      "Trial 61 RUNNING\n",
      "Trial 61 COMPLETEDTrial 62 STOPPING_COMPLETED\n",
      "\n",
      "Trial 62 COMPLETED\n",
      "All trials completed. Generating summary report.\n",
      "====================================================================================================\n",
      "Hyperparameter space: {'learning_rate': [0.0001, 0.001]}\n",
      "Trials completed: 2\n",
      "Best validation: {'trial_id': 61, 'hparam_name': 'learning_rate', 'hparam_val': 0.001, 'val_metric_name': 'validation_error', 'best_val_metric': 0.4248202875399361}\n"
     ]
    }
   ],
   "source": [
    "trial_queue = queue.Queue()\n",
    "exp_threads = []\n",
    "\n",
    "for hp_name, hp_vals in hp_search.items():\n",
    "    for hp_val in hp_vals:\n",
    "        exp_thread = threading.Thread(target=create_experiment_with_hparams, args=(hp_name, hp_val, val_metric_name, trial_queue))\n",
    "        exp_threads.append(exp_thread)\n",
    "        exp_thread.start()\n",
    "\n",
    "for thread in exp_threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"All trials completed. Generating summary report.\")\n",
    "trial_vals = []\n",
    "for trial_id in trial_queue.queue:\n",
    "    trial = client.get_trial(trial_id=trial_id)\n",
    "    \n",
    "    # Smaller is better\n",
    "    trial_best_val = trial.summary_metrics[\"validation_metrics\"][val_metric_name][\"min\"]\n",
    "    \n",
    "    for hparam in hp_search.keys():  \n",
    "        trial_vals.append({\n",
    "            \"trial_id\": trial.id,\n",
    "            \"hparam_name\": hparam,\n",
    "            \"hparam_val\": trial.hparams[hparam],\n",
    "            \"val_metric_name\": val_metric_name,\n",
    "            \"best_val_metric\": trial_best_val,\n",
    "        })\n",
    "\n",
    "trial_vals.sort(key=lambda x: x[\"best_val_metric\"])\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(f\"Hyperparameter space: {hp_search}\")\n",
    "print(f\"Trials completed: {len(trial_vals)}\")\n",
    "print(f\"Best validation: {trial_vals[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe15be4c-349d-41ce-aa9a-a879206c7b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-19T21:04:50.912994Z] a658e1d8 || INFO: [29] root: New trial runner in (container a658e1d8-5fed-439e-ab53-7f26e89bdba8) on agent i-0610c08d001e1c06d: {\"bind_mounts\": [], \"checkpoint_policy\": \"best\", \"checkpoint_storage\": {\"access_key\": \"********\", \"bucket\": \"det-python-sdk-demo-us-west-2-573932760021\", \"endpoint_url\": null, \"prefix\": null, \"save_experiment_best\": 0, \"save_trial_best\": 1, \"save_trial_latest\": 1, \"secret_key\": \"********\", \"type\": \"s3\"}, \"data\": {}, \"debug\": false, \"description\": null, \"entrypoint\": \"model_def:CIFARTrial\", \"environment\": {\"image\": {\"cpu\": \"determinedai/environments:py-3.8-pytorch-1.12-tf-2.11-cpu-14cb565\", \"cuda\": \"determinedai/environments:cuda-11.3-pytorch-1.12-tf-2.11-gpu-14cb565\", \"rocm\": \"determinedai/environments:rocm-5.0-pytorch-1.10-tf-2.7-rocm-14cb565\"}, \"environment_variables\": {\"cpu\": [], \"cuda\": [], \"rocm\": []}, \"proxy_ports\": [], \"ports\": {\"trial\": 1734}, \"registry_auth\": null, \"force_pull_image\": false, \"pod_spec\": null, \"add_capabilities\": [], \"drop_capabilities\": []}, \"hyperparameters\": {\"global_batch_size\": {\"type\": \"const\", \"val\": 32}, \"layer1_dropout\": {\"type\": \"const\", \"val\": 0.25}, \"layer2_dropout\": {\"type\": \"const\", \"val\": 0.25}, \"layer3_dropout\": {\"type\": \"const\", \"val\": 0.5}, \"learning_rate\": {\"type\": \"const\", \"val\": 0.0001}, \"learning_rate_decay\": {\"type\": \"const\", \"val\": 1e-06}}, \"labels\": [], \"max_restarts\": 5, \"min_checkpoint_period\": {\"epochs\": 1}, \"min_validation_period\": {\"batches\": 100}, \"name\": \"cifar10_pytorch_const\", \"optimizations\": {\"aggregation_frequency\": 1, \"average_aggregated_gradients\": true, \"average_training_metrics\": true, \"gradient_compression\": false, \"grad_updates_size_file\": null, \"mixed_precision\": \"O0\", \"tensor_fusion_threshold\": 64, \"tensor_fusion_cycle_time\": 5, \"auto_tune_tensor_fusion\": false}, \"perform_initial_validation\": false, \"profiling\": {\"enabled\": false, \"begin_on_batch\": 0, \"end_after_batch\": null, \"sync_timings\": true}, \"project\": \"\", \"records_per_epoch\": 10000, \"reproducibility\": {\"experiment_seed\": 1689800685}, \"resources\": {\"max_slots\": null, \"slots_per_trial\": 1, \"weight\": 1, \"native_parallel\": false, \"shm_size\": null, \"resource_pool\": \"compute-pool\", \"priority\": null, \"devices\": []}, \"scheduling_unit\": 100, \"searcher\": {\"max_length\": {\"epochs\": 1}, \"metric\": \"validation_error\", \"name\": \"single\", \"smaller_is_better\": true, \"source_checkpoint_uuid\": null, \"source_trial_id\": null}, \"workspace\": \"\", \"slurm\": {}, \"pbs\": {}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from determined.common.experimental.trial import LogLevel\n",
    "\n",
    "# Filtering logs -> get all debug logs from specific agent before a specific timestamp.\n",
    "for log in trial.logs(search_text=\"a658e1d8\", min_level=LogLevel.DEBUG):\n",
    "    print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9b870d37-e3f9-48d7-9bee-aad93a8cd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
